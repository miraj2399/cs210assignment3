{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2edde60b",
   "metadata": {},
   "source": [
    "# Problem 2: German Credit Dataset (72 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "86697ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "df = pd.read_csv(\"GermanCredit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6569bc",
   "metadata": {},
   "source": [
    "## **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf1153",
   "metadata": {},
   "source": [
    "### [8 pts] Drop the 3 columns that contribute the least to the dataset. These would be the columns with the highest number of non-zero 'none' values. Break ties by going left to right in columns. (Your code should be generalizable to drop n columns, but for the rest of the analysis, you can call your code for n=3.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "60fc78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1(pre)\n",
    "def drop_n_cols(df,n):\n",
    "\n",
    "    #list of coloumns in data frame\n",
    "    cols = list(df.columns.values)\n",
    "\n",
    "    #creating ad dictionary to store count of 'none' for each column\n",
    "    cols_dict = dict()\n",
    "    for col in cols:\n",
    "        cols_dict[col] = df.loc[df[col] == 'none',col].count()\n",
    "\n",
    "        #Convert the dictionary to Counter to find n entries with highetst 'none' count\n",
    "    cols_dict = Counter(cols_dict)\n",
    "    cols_dict = cols_dict.most_common(3)\n",
    "\n",
    "        #cols_dict is now a list of tuple, drop the desired columns\n",
    "    for tup in cols_dict:\n",
    "        df = df.drop(tup[0],axis=1).copy()\n",
    "    return df\n",
    "df = drop_n_cols(df,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa46fca7",
   "metadata": {},
   "source": [
    "### [4 pts] Certain values in some of the columns contain unnecessary apostrophes (â€˜). Remove the apostrophes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "dd738363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2(pre)\n",
    "#!!!!!!!!!!need verification about the meaning of apostrophe on data set\n",
    "#this function simply remove all apostrophe in the entire dataset\n",
    "def remove_apostrophe(df):\n",
    "    for cols in list(df.columns.values):\n",
    "        df[cols].replace(regex=True,inplace=True,to_replace=r\"'\",value=r'')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f09d734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_apostrophe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c16baf0",
   "metadata": {},
   "source": [
    "###### Helper Method for 2.3-2.6(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "339ad185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper for 2.3 - 2.6(pre)\n",
    "def modify(df,modifying_table,colname):\n",
    "    for tup in modifying_table:\n",
    "        df.loc[df[colname] == tup[0], colname]= tup[1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddab248",
   "metadata": {},
   "source": [
    "### [5 pts] The checking_status column has values in 4 categories: 'no checking', '<0', '0<=X<200', and '>=200'. Change these to 'No Checking', 'Low', 'Medium', and 'High' respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "72daa5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3(pre)\n",
    "def modify_checking_status(df):\n",
    "    modifying_table = [(\"no checking\",\"No checking\"),(\"<0\",\"Low\"),(\"0<=X<200\",\"Medium\"),(\">=200\",\"High\")]\n",
    "    df = modify(df,modifying_table,\"checking_status\")\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "9f7fbbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = modify_checking_status(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d416f9",
   "metadata": {},
   "source": [
    "### [5 pts] The savings_status column has values in 4 categories: 'no known savings', '<100', '100<=X<500', '500<=X<1000', and '>=1000'. Change these to 'No Savings', 'Low', 'Medium', 'High', and 'High' respectively. (Yes, the last two are both 'High')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "d16b4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4(pre)\n",
    "def modify_savings_status(df):\n",
    "    modifying_table = [(\"no known savings\",\"No Savings\"),(\"<100\",\"Low\"),(\"100<=X<500\",\"Medium\"),(\"500<=X<1000\",\"High\"),(\">=1000\",\"High\")]\n",
    "    return modify(df,modifying_table,'savings_status')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "cab6a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = modify_savings_status(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8dbd5",
   "metadata": {},
   "source": [
    "### [4 pts] Change class column values from 'good' to '1' and 'bad' to '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "fa4b6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5(pre)\n",
    "def modify_class(df):\n",
    "    modifying_table = [(\"good\",\"1\"),(\"bad\",\"0\")]\n",
    "    return modify(df,modifying_table,\"class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "53216570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = modify_class(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed9cf6",
   "metadata": {},
   "source": [
    "### [5 pts] Change the employment column value 'unemployed' to 'Unemployed', and for the others, change to 'Amateur', 'Professional', 'Experienced' and 'Expert', depending on year range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "271b8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.6(pre)\n",
    "def modify_employment(df):\n",
    "    modifying_table = [('umemployed',\"Unemployed\"),(\"<1\",\"Amatuer\"),(\"1<=X<4\",\"Professional\"),(\"4<=X<7\",\"Experienced\"),(\">=7\",\"Expert\")]\n",
    "    return modify(df,modifying_table,\"employment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "068d5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = modify_employment(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c1f2db",
   "metadata": {},
   "source": [
    "## **Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc2170",
   "metadata": {},
   "source": [
    "### [5 pts] Often we need to find correlations between categorical attributes, i.e. attributes that have values that fall in one of several categories, such as \"yes\"/\"no\" for attr1, or \"low\",\"medium\",\"high\" for attr2.\n",
    "One such correlation is to find counts in combinations of categorial values across attributes, as in how many instances are \"yes\" for attr1 and \"low\" for attr2. A good way to find such counts is to use the Pandas crosstab function. Do this for the following two counts.\n",
    "#### a)[3 pts] Get the count of each category of foreign workers (yes and no) for each class of credit (good and bad).\n",
    "#### b)[2 pts] Similarly, get the count of each category of employment for each category of saving_status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "eff6a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 a (ana)\n",
    "def correl_foreign_class(df):\n",
    "    return pd.crosstab(df['foreign_worker'],df['class']).rename(columns={'0':\"bad\",\"1\":\"good\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "fc5ff5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = correl_foreign_class(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "0023f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 b (ana)\n",
    "def correl_employment_saving(df):\n",
    "    return pd.crosstab(df['employment'],df['savings_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "4b5164b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 =correl_employment_saving(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944074a1",
   "metadata": {},
   "source": [
    "### [4 pts] Find the average credit_amount of single males that have 4<=X<7 years of employment. You can leave the raw result as is, no need for rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e55f054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 (ana)\n",
    "## 4<=X<7 was updated to \"Experienced\"\n",
    "average_credit_amount = df.loc[(df['personal_status'] == 'male single') & (df['employment']=='Experienced')].credit_amount.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a49cb2",
   "metadata": {},
   "source": [
    "### [4 pts] Find the average credit duration for each of the job types. You can leave the raw result as is, no need for rounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "0bf42be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 (ana)\n",
    "avg_duration_job = df.groupby('job')['duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "68706d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job\n",
       "high qualif/self emp/mgmt    25.168919\n",
       "skilled                      21.411111\n",
       "unemp/unskilled non res      17.363636\n",
       "unskilled resident           16.535000\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_duration_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da536fb",
   "metadata": {},
   "source": [
    "### [4 pts] For the purpose 'education', what is the most common checking_status and savings_status? Your code should print:\n",
    "    Most common checking status: ...\n",
    "    Most common savings status: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "bb21b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5(ana)\n",
    "mc_checking = str(df.loc[(df['purpose']=='education'),['checking_status']].mode().iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "b646f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common checking status:  No checking\n"
     ]
    }
   ],
   "source": [
    "print(\"Most common checking status: \",mc_checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "39fdbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_saving = str(df.loc[(df['purpose']=='education'),['savings_status']].mode().iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "37f63ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common savings status:  Low\n"
     ]
    }
   ],
   "source": [
    "print(\"Most common savings status: \",mc_saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee11c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
